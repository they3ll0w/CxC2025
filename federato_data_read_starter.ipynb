{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236ecda-366d-4edb-967c-dbf7cc2893e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import ijson\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#file year \n",
    "year = 2025\n",
    "file_path = f\"new_amplitude_export_{year}.json\"\n",
    "\n",
    "#non-empty columns\n",
    "columns_keep = [\n",
    "    \"$insert_id\",\n",
    "    \"amplitude_id\",\n",
    "    \"app\",\n",
    "    \"city\",\n",
    "    \"client_event_time\",\n",
    "    \"client_upload_time\",\n",
    "    \"country\",\n",
    "    \"data\",\n",
    "    \"data_type\",\n",
    "    \"device_family\",\n",
    "    \"device_id\",\n",
    "    \"device_type\",\n",
    "    \"dma\",\n",
    "    \"event_id\",\n",
    "    \"event_properties\",\n",
    "    \"event_time\",\n",
    "    \"event_type\",\n",
    "    \"language\",\n",
    "    \"library\",\n",
    "    \"os_name\",\n",
    "    \"os_version\",\n",
    "    \"platform\",\n",
    "    \"processed_time\",\n",
    "    \"region\",\n",
    "    \"server_received_time\",\n",
    "    \"server_upload_time\",\n",
    "    \"session_id\",\n",
    "    \"user_id\",\n",
    "    \"user_properties\",\n",
    "    \"uuid\",\n",
    "]\n",
    "path = Path(f\"{year}_csv\")\n",
    "if not path.exists():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "#use ijson to read the json files efficiently in memory\n",
    "with open(file_path, \"r\") as f:\n",
    "    objects = ijson.items(f, \"item\") #creates a generator object\n",
    "    \n",
    "    batch_size = 100000 #can be updated, currently saves per batches of 100,000\n",
    "    chunk = []\n",
    "    count = 0 #used to index batch file\n",
    "    for obj in objects:\n",
    "        chunk.append(obj)\n",
    "        if len(chunk) >= batch_size:\n",
    "            df = pd.DataFrame(chunk)\n",
    "            output_csv = f\"{year}_csv/{file_path.split('.')[0]}_chunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "            df = df[columns_keep] #remove empty columns\n",
    "            df.to_csv(output_csv, index=False)\n",
    "            count += 1\n",
    "            chunk = []\n",
    "\n",
    "    if chunk: #process remaining data if any\n",
    "        output_csv = f\"{year}_csv/{file_path.split('.')[0]}_chunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "        df = pd.DataFrame(chunk)\n",
    "        df = df[columns_keep]\n",
    "        df.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04213331-46fc-470f-a8a5-3c27569c3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import ijson\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "#file chunk \n",
    "part = 1\n",
    "file_path = f\"new_export/amplitude_export_chunk_{part}_anonymized.json\"\n",
    "\n",
    "#non-empty columns\n",
    "columns_keep = [\n",
    "    \"$insert_id\",\n",
    "    \"amplitude_id\",\n",
    "    \"app\",\n",
    "    \"city\",\n",
    "    \"client_event_time\",\n",
    "    \"client_upload_time\",\n",
    "    \"country\",\n",
    "    \"data\",\n",
    "    \"data_type\",\n",
    "    \"device_family\",\n",
    "    \"device_id\",\n",
    "    \"device_type\",\n",
    "    \"dma\",\n",
    "    \"event_id\",\n",
    "    \"event_properties\",\n",
    "    \"event_time\",\n",
    "    \"event_type\",\n",
    "    \"language\",\n",
    "    \"library\",\n",
    "    \"os_name\",\n",
    "    \"os_version\",\n",
    "    \"platform\",\n",
    "    \"processed_time\",\n",
    "    \"region\",\n",
    "    \"server_received_time\",\n",
    "    \"server_upload_time\",\n",
    "    \"session_id\",\n",
    "    \"user_id\",\n",
    "    \"user_properties\",\n",
    "    \"uuid\",\n",
    "]\n",
    "\n",
    "path = Path(f\"{part}_csv\")\n",
    "if not path.exists():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#use ijson to read the json files efficiently in memory\n",
    "with open(file_path, \"r\") as f:\n",
    "    objects = ijson.items(f, \"item\") #creates a generator object\n",
    "    \n",
    "    batch_size = 100000 #can be updated, currently saves per batches of 100,000\n",
    "    chunk = []\n",
    "    count = 0 #used to index batch file\n",
    "    for obj in objects:\n",
    "        chunk.append(obj)\n",
    "        if len(chunk) >= batch_size:\n",
    "            df = pd.DataFrame(chunk)\n",
    "            output_csv = f\"{part}_csv/{file_path.split('/')[1].split('.')[0]}_subchunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "            df = df[columns_keep] #remove empty columns\n",
    "            df.to_csv(output_csv, index=False)\n",
    "            count += 1\n",
    "            chunk = []\n",
    "\n",
    "    if chunk: #process remaining data if any\n",
    "        output_csv = f\"{part}_csv/{file_path.split('/')[1].split('.')[0]}_subchunk_{count*batch_size}_{(count+1)*batch_size}.csv\"\n",
    "        df = pd.DataFrame(chunk)\n",
    "        print(df.shape)\n",
    "        df = df[columns_keep]\n",
    "        print(df.shape)\n",
    "        df.to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0966e73-fcd6-4175-8cd2-7a93594bf7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
